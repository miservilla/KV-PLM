{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michaelservilla/anaconda3/envs/KV3.7/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3438, -0.3295,  0.6055,  ..., -0.8003,  0.7506, -0.9564]],\n",
      "\n",
      "        [[ 0.2173,  0.3115,  0.8765,  ..., -0.5578, -0.9999,  0.8114]],\n",
      "\n",
      "        [[-0.1347,  0.1341, -0.4735,  ...,  0.2004,  0.9947, -0.7683]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.9735,  0.1412,  0.9315,  ..., -0.2090,  0.9816,  0.4636]],\n",
      "\n",
      "        [[ 0.0212, -0.2899, -0.9932,  ...,  0.7406,  0.6677, -0.9412]],\n",
      "\n",
      "        [[-0.8827, -0.0494, -0.7055,  ...,  0.5038,  0.7931, -0.9974]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the data\n",
    "data = torch.load('def_embeddings.pt')\n",
    "\n",
    "# Inspect the data\n",
    "print(data)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([924, 1, 768])\n"
     ]
    }
   ],
   "source": [
    "if torch.is_tensor(data):\n",
    "    print(data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = 'ChEBI_id_name_SMILES_combined_def.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Assuming 'chebi_id_column' is the column name with ChEBI IDs\n",
    "chebi_ids = df['ChEBI ID'].tolist()\n",
    "\n",
    "# Your tensor data\n",
    "# Assuming 'data' is your tensor of shape [924, 1, 768]\n",
    "data = torch.load('def_embeddings.pt')\n",
    "\n",
    "# Initialize the dictionary\n",
    "embedding_dict = {}\n",
    "\n",
    "# Iterate over the ChEBI IDs and tensor data\n",
    "for i, chebi_id in enumerate(chebi_ids):\n",
    "    # Squeeze to remove the singleton dimension and convert to list or numpy array if necessary\n",
    "    embedding = data[i].squeeze().tolist()  # Use .numpy() instead of .tolist() if you prefer numpy array\n",
    "    embedding_dict[chebi_id] = embedding\n",
    "\n",
    "# Now embedding_dict contains ChEBI IDs as keys and their embeddings as values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before pickling, type: <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before pickling, type: {type(embedding_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved to embedding_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Ensure embedding_dict is the dictionary you've just verified\n",
    "save_path = 'embedding_dict.pkl'  # Adjusted path for file accessibility\n",
    "\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(embedding_dict, f)\n",
    "\n",
    "print(f\"Dictionary saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pickling, type: <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"After pickling, type: {type(embedding_dict)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded object type: <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "with open(save_path, 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded object type: {type(loaded_dict)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'loaded_dict' is your loaded dictionary\n",
    "for key, value in loaded_dict.items():\n",
    "    print(f\"Key: {key}, Value: {value[:770]}\")  # Print the key and the first 10 elements of the value\n",
    "    # break  # Remove or adjust this if you want to see more\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall length of the first value: 768\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_453020/1103110141.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# If first_value is a list or similar, check the length of its first element (if applicable)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_value\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Length of the first element in the first value: {len(first_value[0])}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Print the type to understand the data structure better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "# Inspect the first value in more detail\n",
    "first_key = next(iter(loaded_dict))\n",
    "first_value = loaded_dict[first_key]\n",
    "\n",
    "# Check the overall length of the first_value\n",
    "print(f\"Overall length of the first value: {len(first_value)}\")\n",
    "\n",
    "# If first_value is a list or similar, check the length of its first element (if applicable)\n",
    "if isinstance(first_value, list) and len(first_value) > 0:\n",
    "    print(f\"Length of the first element in the first value: {len(first_value[0])}\")\n",
    "\n",
    "# Print the type to understand the data structure better\n",
    "print(f\"Type of the first value: {type(first_value)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KV3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
